{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cde7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1db016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yagya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb9afce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yagya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b51bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yagya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b915c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('nlp_disaster_tweets_train.csv')\n",
    "x_test=pd.read_csv('nlp_disaster_tweets_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f96903a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data['target']\n",
    "data=data.iloc[:,:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ac6d3",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308c82e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db0d63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 238.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741b420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebdc17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count   7613.000000\n",
       "mean    5441.934848\n",
       "std     3137.116090\n",
       "min        1.000000\n",
       "25%     2734.000000\n",
       "50%     5408.000000\n",
       "75%     8146.000000\n",
       "max    10873.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e72213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83de05f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                    104\n",
       "New York                71\n",
       "United States           50\n",
       "London                  45\n",
       "Canada                  29\n",
       "                      ... \n",
       "MontrÌ©al, QuÌ©bec       1\n",
       "Montreal                 1\n",
       "ÌÏT: 6.4682,3.18287      1\n",
       "Live4Heed??              1\n",
       "Lincoln                  1\n",
       "Name: location, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77b79e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f06e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['location'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b950bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagya\\AppData\\Local\\Temp/ipykernel_6752/587202063.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['keyword'][n]=str(data['keyword'][n])\n"
     ]
    }
   ],
   "source": [
    "#Train data\n",
    "n=0\n",
    "for n in range(len(data)):\n",
    "    data['keyword'][n]=str(data['keyword'][n])\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37e2fe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagya\\AppData\\Local\\Temp/ipykernel_6752/2675171194.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test['keyword'][n]=str(x_test['keyword'][n])\n"
     ]
    }
   ],
   "source": [
    "#Test data\n",
    "n=0\n",
    "for n in range(len(x_test)):\n",
    "    x_test['keyword'][n]=str(x_test['keyword'][n])\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b6e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "i=0\n",
    "concat_texts=[]\n",
    "for i in range(len(data)):\n",
    "    concat_texts.append(\" \".join((data['text'][i],data['keyword'][i])))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dfde124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "i=0\n",
    "concat_texts_test=[]\n",
    "for i in range(len(x_test)):\n",
    "    concat_texts_test.append(\" \".join((x_test['text'][i],x_test['keyword'][i])))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e66e0",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21623049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "tokenized_sentences=[]\n",
    "for sent in concat_texts:\n",
    "    tokenized_sentences.append(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ad6712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "tokenized_sentences_test=[]\n",
    "for sent in concat_texts_test:\n",
    "    tokenized_sentences_test.append(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13508e",
   "metadata": {},
   "source": [
    "# Lower case conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3861375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "for sent in tokenized_sentences:\n",
    "    m=0\n",
    "    while m<len(sent):\n",
    "        sent[m] = re.sub(r\"[^a-zA-Z0-9]\", \" \", sent[m].lower())\n",
    "        m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9debc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "for sent in tokenized_sentences_test:\n",
    "    m=0\n",
    "    while m<len(sent):\n",
    "        sent[m] = re.sub(r\"[^a-zA-Z0-9]\", \" \", sent[m].lower())\n",
    "        m=m+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1cbfa",
   "metadata": {},
   "source": [
    "# Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5da8cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en=stopwords.words('english')\n",
    "stopwords_en.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885742d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "words=[]\n",
    "for sent in tokenized_sentences:\n",
    "    words.append([w for w in sent if w not in stopwords_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd04b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "words_test=[]\n",
    "for sent in tokenized_sentences_test:\n",
    "    words_test.append([w for w in sent if w not in stopwords_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727ccb2",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a46365ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "for sent in words:\n",
    "    i=0\n",
    "    while i<len(sent):\n",
    "        sent[i]=(PorterStemmer().stem(sent[i]))\n",
    "        i=i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bf92ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "for sent in words_test:\n",
    "    i=0\n",
    "    while i<len(sent):\n",
    "        sent[i]=(PorterStemmer().stem(sent[i]))\n",
    "        i=i+1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab8277",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d5f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for sent in words:\n",
    "    i=0\n",
    "    while i<len(sent):\n",
    "        all_words.append(sent[i])\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e711073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq={}\n",
    "for word in all_words:\n",
    "    if word not in words_freq.keys():\n",
    "        words_freq[word]=1\n",
    "    elif word in words_freq.keys():\n",
    "        words_freq[word]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de52ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "most_freq = heapq.nlargest(10000, words_freq, key=words_freq.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31bf8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "sentence_vectors = []\n",
    "for sentence in words:\n",
    "    sent_vec = []\n",
    "    for token in most_freq:\n",
    "        if token in sentence:\n",
    "            sent_vec.append(1)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    sentence_vectors.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d630675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "sentence_vectors_test = []\n",
    "for sentence in words_test:\n",
    "    sent_vec_test = []\n",
    "    for token in most_freq:\n",
    "        if token in sentence:\n",
    "            sent_vec_test.append(1)\n",
    "        else:\n",
    "            sent_vec_test.append(0)\n",
    "    sentence_vectors_test.append(sent_vec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24aa4d",
   "metadata": {},
   "source": [
    "# Developing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c36a42",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "caa7100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0055759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(sentence_vectors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6806b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=knn.predict(sentence_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51ec4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eec1bd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2388\n",
       "1     875\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef514ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('preds_knn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9644d57",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "36109cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(sentence_vectors,y_train)\n",
    "lr_preds=lr.predict(sentence_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f12679f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds=pd.DataFrame(lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f82b75d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2055\n",
       "1    1208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14582475",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds.to_csv('preds_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99d388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
